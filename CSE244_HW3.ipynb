{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"CSE244_HW3.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a0859cccf25841608867f02dcda7f048":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b37b115888f04e2ca695c1c7bdf5aad6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_df9ed21c1d7b481c8dc779a37486b3ac","IPY_MODEL_9ee3e54e839f4e3c8b31d6998c022c6f"]}},"b37b115888f04e2ca695c1c7bdf5aad6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"df9ed21c1d7b481c8dc779a37486b3ac":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0444db0688fa4e86a4cd6153163c5947","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ab4f95d2d04445509668811ba7d3824d"}},"9ee3e54e839f4e3c8b31d6998c022c6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d13fcb7437d9486d9f4c8b697d527fac","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 232k/232k [00:00&lt;00:00, 420kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a82cb3d832aa43518202629a831da652"}},"0444db0688fa4e86a4cd6153163c5947":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ab4f95d2d04445509668811ba7d3824d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d13fcb7437d9486d9f4c8b697d527fac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a82cb3d832aa43518202629a831da652":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"euWz4ZM5q5v7","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import pandas as pd\n","import numpy as np\n","import collections\n","from nltk.stem import PorterStemmer "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NGXeEEFErL0q","colab_type":"code","outputId":"acdc3e9a-b306-40d3-e4e7-d2ecda29e83e","executionInfo":{"status":"ok","timestamp":1583720089190,"user_tz":420,"elapsed":13572,"user":{"displayName":"Zhengqi Liu","photoUrl":"","userId":"15345161738032684956"}},"colab":{"base_uri":"https://localhost:8080/","height":658}},"source":["! pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n","\r\u001b[K     |▋                               | 10kB 14.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 2.0MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 2.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40kB 1.8MB/s eta 0:00:01\r\u001b[K     |███▎                            | 51kB 2.2MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 81kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 102kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 112kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 122kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 133kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 143kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 153kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 163kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 174kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 184kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 194kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 204kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 215kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 225kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 235kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 245kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 256kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 266kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 276kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 286kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 296kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 307kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 317kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 327kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 337kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 348kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 358kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 368kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 378kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 389kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 399kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 409kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 419kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 430kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 440kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 450kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 460kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 471kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 481kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 491kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 501kB 2.9MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n","\u001b[K     |████████████████████████████████| 870kB 42.3MB/s \n","\u001b[?25hCollecting tokenizers==0.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n","\u001b[K     |████████████████████████████████| 3.7MB 35.2MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 39.4MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=e95818fb24464b532122a0ddc41379ff1da9f2999ea2e0281bcb3aa8dcdb90cd\n","  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IE4g9mXbUAJo","colab_type":"code","outputId":"dcbe6de6-2a61-49a1-d147-48a96dddde89","executionInfo":{"status":"ok","timestamp":1583720136182,"user_tz":420,"elapsed":3729,"user":{"displayName":"Zhengqi Liu","photoUrl":"","userId":"15345161738032684956"}},"colab":{"base_uri":"https://localhost:8080/","height":302}},"source":["! nvidia-smi"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Mon Mar  9 02:15:33 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.59       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gJ2TL9Pcq_TX","colab_type":"code","outputId":"0d34c18f-2054-4130-ab13-909281d82d28","executionInfo":{"status":"ok","timestamp":1583720115488,"user_tz":420,"elapsed":2586,"user":{"displayName":"Zhengqi Liu","photoUrl":"","userId":"15345161738032684956"}},"colab":{"base_uri":"https://localhost:8080/","height":79}},"source":["from transformers import *"],"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"XYlPJt8-q5wE","colab_type":"code","colab":{}},"source":["file_utterance = open(\"hw2_utterance_dev.txt\", 'r')\n","utterances_dev = []\n","for line in file_utterance.readlines():\n","    utterances_dev.append(line[:-1])\n","file_tag = open(\"hw2_tags_dev.txt\", \"r\")\n","tags_dev = []\n","for line in file_tag.readlines():\n","    tags_dev.append(line[:-1])\n","\n","data = pd.read_csv('hw2_train.csv')\n","utterances_train = data['utterances']\n","tags_train = data['IOB Slot tags']\n","utterances_train = list(utterances_train) + utterances_dev\n","tags_train = list(tags_train) + tags_dev"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLSpQbd9kc9J","colab_type":"code","outputId":"1be510ff-bf43-4d06-efb4-961c686a6884","executionInfo":{"status":"ok","timestamp":1583720149443,"user_tz":420,"elapsed":3050,"user":{"displayName":"Zhengqi Liu","photoUrl":"","userId":"15345161738032684956"}},"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["a0859cccf25841608867f02dcda7f048","b37b115888f04e2ca695c1c7bdf5aad6","df9ed21c1d7b481c8dc779a37486b3ac","9ee3e54e839f4e3c8b31d6998c022c6f","0444db0688fa4e86a4cd6153163c5947","ab4f95d2d04445509668811ba7d3824d","d13fcb7437d9486d9f4c8b697d527fac","a82cb3d832aa43518202629a831da652"]}},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a0859cccf25841608867f02dcda7f048","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jbTX_N5KTQuL","colab_type":"code","colab":{}},"source":["def count_tag(data):\n","  tag_counter = collections.defaultdict(int)\n","  for tag in data:\n","      for t in tag.split():\n","          tag_counter[t] += 1\n","        \n","  tag_to_index = {'[PAD]' : 0}\n","  for k,v in sorted(tag_counter.items(), reverse=True, key=lambda kv:(kv[1], kv[0])):\n","      tag_to_index[k] = len(tag_to_index)\n","\n","  index_to_tag = {}\n","  for k,v in tag_to_index.items():\n","      index_to_tag[v] = k\n","    \n","  return tag_to_index, index_to_tag\n","  \n","tag_to_index, index_to_tag = count_tag(tags_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LrUjf84Frl4U","colab_type":"code","outputId":"35d6c6c7-6378-4c0e-f9fa-c2b3efd346a8","executionInfo":{"status":"ok","timestamp":1583720160825,"user_tz":420,"elapsed":9210,"user":{"displayName":"Zhengqi Liu","photoUrl":"","userId":"15345161738032684956"}},"colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["def prepare(sentence, tag):\n","  MAX_LEN = 30\n","  sentence = sentence.split(\" \")\n","  tag = tag.split(\" \")\n","  while len(sentence) != len(tag):\n","    for i in range(len(sentence)):\n","      if sentence[i][0] == \"'\":\n","          temp = sentence[i-1] + sentence[i]\n","          sentence = sentence[:i-1] + [temp] + sentence[i+1:]\n","          break\n","  for i in range(len(sentence)):\n","    if sentence[i] == \"'s\":\n","      sentence[i] = \"is\"\n","#  while len(sentence) < 30:\n","#    sentence.append('[PAD]')\n","#    tag.append('[PAD]')\n","  sentence = ' '.join(sentence)\n","  sentence = torch.tensor(tokenizer.encode(sentence, add_special_tokens=True, max_length=30, pad_to_max_length=True)).unsqueeze(0)\n","  while len(tag) < 30:\n","      tag.append('[PAD]')\n","  tag = torch.tensor([tag_to_index[i] for i in tag])\n","  return sentence.cuda(), tag.cuda()\n","prepare(utterances_train[3], tags_train[3])\n"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 101, 2424, 1996, 2931, 3883, 2013, 1996, 3185, 2016, 2003, 1996, 2158,\n","           102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0]], device='cuda:0'),\n"," tensor([1, 1, 1, 1, 1, 1, 1, 3, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0], device='cuda:0'))"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"gO5lC1halhjq","colab_type":"code","colab":{}},"source":["class LSTMTagger(nn.Module):\n","\n","\n","    def __init__(self, embedding_dim, hidden_dim, tagset_size):\n","        super(LSTMTagger, self).__init__()\n","        self.hidden_dim = hidden_dim\n","\n","        # The LSTM takes word embeddings as inputs, and outputs hidden states\n","        # with dimensionality hidden_dim.\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n","\n","        # The linear layer that maps from hidden state space to tag space\n","        self.hidden2tag = nn.Linear(hidden_dim*2, tagset_size)\n","\n","    def forward(self, sentence):\n","        lstm_out, _ = self.lstm(sentence.view(len(sentence), 1, -1))\n","        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n","        tag_scores = F.log_softmax(tag_space, dim=1)\n","        return tag_scores"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3E75VVA5q5wP","colab_type":"code","outputId":"4001394a-37c5-4342-aeca-10a55a4674a0","executionInfo":{"status":"ok","timestamp":1583726078672,"user_tz":420,"elapsed":4249015,"user":{"displayName":"Zhengqi Liu","photoUrl":"","userId":"15345161738032684956"}},"colab":{"base_uri":"https://localhost:8080/","height":521}},"source":["bert = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=100 ).cuda()\n","loss_funtion = nn.CrossEntropyLoss()\n","model = LSTMTagger(100, 200, len(tag_to_index)).cuda()\n","optimizer = optim.Adam(model.parameters())\n","for epoch in range(30):\n","    total_loss = 0\n","    for i in range(len(utterances_train)):\n","        sentence, tag = prepare(utterances_train[i], tags_train[i])\n","        bert_outputs = bert(sentence)[0].view(30,-1)\n","        model.zero_grad()\n","        outputs = model(bert_outputs)\n","        loss = loss_funtion(outputs, tag)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss\n","    \n","    print(\"epoch=\", epoch, \"loss=\", total_loss/len(data))\n","        "],"execution_count":16,"outputs":[{"output_type":"stream","text":["epoch= 0 loss= tensor(0.1884, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 1 loss= tensor(0.0898, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 2 loss= tensor(0.0630, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 3 loss= tensor(0.0446, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 4 loss= tensor(0.0289, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 5 loss= tensor(0.0195, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 6 loss= tensor(0.0138, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 7 loss= tensor(0.0116, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 8 loss= tensor(0.0079, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 9 loss= tensor(0.0066, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 10 loss= tensor(0.0059, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 11 loss= tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 12 loss= tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 13 loss= tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 14 loss= tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 15 loss= tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 16 loss= tensor(0.0025, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 17 loss= tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 18 loss= tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 19 loss= tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 20 loss= tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 21 loss= tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 22 loss= tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 23 loss= tensor(0.0021, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 24 loss= tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 25 loss= tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 26 loss= tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 27 loss= tensor(0.0016, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 28 loss= tensor(0.0023, device='cuda:0', grad_fn=<DivBackward0>)\n","epoch= 29 loss= tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EU1ke_Xcq5wV","colab_type":"code","outputId":"27e7b21d-cbc7-46fa-fcf6-36466fde6e1e","executionInfo":{"status":"ok","timestamp":1583726368112,"user_tz":420,"elapsed":1201,"user":{"displayName":"Zhengqi Liu","photoUrl":"","userId":"15345161738032684956"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["def predict(sentence, tag):\n","    tag_length = len(tag.split(\" \"))\n","    sentence, tag = prepare(sentence, tag)\n","    bert_output = bert(sentence)[0].view(30,-1)\n","    output = model(bert_output)\n","    res = []\n","    for line in output:\n","        line = list(line)\n","        res.append(index_to_tag[line.index(max(line))])\n","    \n","    return res[:tag_length]\n","print(utterances_train[0])\n","print(predict(utterances_train[0], tags_train[0]))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["who plays luke on star wars new hope\n","['O', 'O', 'B_char', 'O', 'B_movie', 'I_movie', 'I_movie', 'I_movie']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q_FpaZpGq5wZ","colab_type":"code","colab":{}},"source":["file_test = open('hw2_utterance_test.txt', 'r')\n","file_token = open('hw2_tokens_test.txt', 'r')\n","test_token = []\n","for line in file_token.readlines():\n","    test_token.append(line[:-1])\n","\n","test = []\n","for line in file_test.readlines():\n","    test.append(line[:-1])\n","output = []\n","with torch.no_grad():\n","    for i in range(len(test)):\n","      try:\n","        res = predict(test[i], test_token[i])\n","        output.append(res)\n","      except:\n","        output.append(['O']*len(test_token[i].split(\" \")))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yX5aeKbrq5wd","colab_type":"code","colab":{}},"source":["with open('prediction.txt', 'w') as f:\n","    for line in output:\n","        f.write(' '.join(line))\n","        f.write('\\n')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ReSvH5bC12x8","colab_type":"code","outputId":"38143393-ed57-4f8f-db45-5bfc58e646cc","executionInfo":{"status":"ok","timestamp":1583726449631,"user_tz":420,"elapsed":4202,"user":{"displayName":"Zhengqi Liu","photoUrl":"","userId":"15345161738032684956"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["! python3 evaluation.py"],"execution_count":20,"outputs":[{"output_type":"stream","text":["F1 Score is 100.00%\n"],"name":"stdout"}]}]}